
import subprocess
import pandas as pd                     # for working with dataframes
from datetime import date               # for obtaining current date
import json
import gc
import requests
import re


# define filenames
Original_report_name = "vulnerability-report-kaptain-main.csv"
Resulting_report_name = f"grype-report-kaptain-{date.today()}.csv"
Available_columns_file_name = "grype-fields-list.txt"


# declare variables
Needed_columns = [
    'image.name',
    'resource_purl',
    'vulnerability.id', 
    'vulnerability.dataSource', 
    'artifact.purl', 
    'vulnerability.fix.state', 
    'vulnerability.description', 
    'artifact.metadata.virtualPath',
    'vulnerability.fix.versions'
    ]


# Create dataframe for storing the final results
Final_Results_df = pd.DataFrame(columns=Needed_columns)


# Load CVE reporter report 
Original_Report_df = pd.read_csv(Original_report_name, header=0)

# Filter CVE reporter report by 'critical' CVEs only
Original_Report_df = Original_Report_df[Original_Report_df['vulnerability_severity'] == 'critical']

# Discard unnecesary columns from CVE reporter report
Original_Report_df = Original_Report_df[['resource_purl', 'vulnerability_name', 'mitigation_url', 'vulnerability_severity']]

# split vulnerability_name into vulnerability_CVE and vulnerability_GHSA
Original_Report_df['vulnerabiligy_CVE'] = None
Original_Report_df['vulnerability_GHSA'] = None
Original_Report_df.loc[Original_Report_df['vulnerability_name'].str.contains(r'(CVE)'), 'vulnerabiligy_CVE'] = Original_Report_df['vulnerability_name'].loc[Original_Report_df['vulnerability_name'].str.contains(r'(CVE)')]
Original_Report_df.loc[Original_Report_df['vulnerability_name'].str.contains(r'(GHSA)'), 'vulnerability_GHSA'] = Original_Report_df['vulnerability_name'].loc[Original_Report_df['vulnerability_name'].str.contains(r'(GHSA)')]

# fill the vulnerability_CVE column with corresponding CVE ID using vulnerability_GHSA
for index, row in Original_Report_df.iterrows():
    if row['vulnerabiligy_CVE'] is None and row['vulnerability_GHSA'] is not None:
        vuln_GHSA = row['vulnerability_GHSA']
        url = 'https://github.com/advisories/' + vuln_GHSA
        regex_pattern = 'CVE-[0-9-]*'
        r = requests.get(url, allow_redirects=True)
        vuln_CVE = re.findall(regex_pattern, r.text)
        if len(vuln_CVE) > 0:
            Original_Report_df.at[index,'vulnerabiligy_CVE'] = vuln_CVE[0]

# Create separate series for iteration
Iterable_list_of_images = pd.Series(Original_Report_df['resource_purl'])
Iterable_list_of_images = pd.Series(Iterable_list_of_images.unique())
Iterable_list_of_images = Iterable_list_of_images[~Iterable_list_of_images.str.contains('mesosphere/kubeflow-dev')]
Iterable_list_of_images = Iterable_list_of_images.reset_index(drop=True)

# Create a separate set for available columns from grype
Available_columns = set()

print("Total images:", len(Iterable_list_of_images))

for index, image in Iterable_list_of_images.items():

    print("Image", index + 1, image)


    # Create dataframe to store results for current image
    Filtered_img_CVEs_df = pd.DataFrame()


    # Format image string
    Pullable_image_name = image.replace("pkg:docker/", "")
    Pullable_image_name = Pullable_image_name.replace("@", ":")
    regex = "?repository_url="
    Split_parts = Pullable_image_name.split(regex)
    if len(Split_parts) > 1:
        Pullable_image_name = Split_parts[1] + "/" + Split_parts[0]
    else:
        Pullable_image_name = Split_parts[0]


    # Run grype scan on image
    Grype_run = subprocess.run(["./CVEs-to-CSVs.sh", Pullable_image_name.strip()], capture_output=True)


    # Load scan results in dataframe
    Current_img_CVEs_json = json.loads(Grype_run.stdout.decode('utf8'))
    Current_img_CVEs_df = pd.json_normalize(Current_img_CVEs_json['matches'])


    # Add all available columns from the dataframe to the available columns:
    Available_columns.update(Current_img_CVEs_df.columns)    
    
    
    # Add the image name and resource purl to the results
    Current_img_CVEs_df['image.name'] = Pullable_image_name
    Current_img_CVEs_df['resource_purl'] = image


    # extraer las columnas requeridas del resultado del scan
    for col in Current_img_CVEs_df:
        for needed_col in Needed_columns:
            if needed_col in Current_img_CVEs_df.columns:
                Filtered_img_CVEs_df[needed_col] = Current_img_CVEs_df[needed_col]


    # Add image results to final results
    Final_Results_df = pd.concat([Final_Results_df, Filtered_img_CVEs_df], ignore_index=True)


    gc.collect()


# split vulnerability.id from Final_Results_df into vulnerability_CVE and vulnerability_GHSA
Final_Results_df['vulnerabiligy_CVE'] = None
Final_Results_df['vulnerability_GHSA'] = None
Final_Results_df.loc[Final_Results_df['vulnerability.id'].str.contains(r'(CVE)'), 'vulnerabiligy_CVE'] = Final_Results_df['vulnerability.id'].loc[Final_Results_df['vulnerability.id'].str.contains(r'(CVE)')]
Final_Results_df.loc[Final_Results_df['vulnerability.id'].str.contains(r'(GHSA)'), 'vulnerability_GHSA'] = Final_Results_df['vulnerability.id'].loc[Final_Results_df['vulnerability.id'].str.contains(r'(GHSA)')]

# fill the vulnerability_CVE column with corresponding CVE ID using vulnerability_GHSA
for index, row in Final_Results_df.iterrows():
    if row['vulnerabiligy_CVE'] is None and row['vulnerability_GHSA'] is not None:
        vuln_GHSA = row['vulnerability_GHSA']
        url = 'https://github.com/advisories/' + vuln_GHSA
        regex_pattern = 'CVE-[0-9-]*'
        r = requests.get(url, allow_redirects=True)
        vuln_CVE = re.findall(regex_pattern, r.text)
        if len(vuln_CVE) > 0:
            Final_Results_df.at[index,'vulnerabiligy_CVE'] = vuln_CVE[0]



# add columns from final report to original report
Final_Results_df = pd.merge(
    Original_Report_df, 
    Final_Results_df, 
    how='left', 
    left_on=['resource_purl', 'vulnerabiligy_CVE'],
    right_on=['resource_purl', 'vulnerabiligy_CVE'],
    suffixes=("_left", "_right"),
    indicator=True)

# quitar los resultados que solo est√©n presentes en grype y no en el CVE reporter
Final_Results_df = Final_Results_df[Final_Results_df['_merge'] != 'right_only']

# split artifact.purl column into affected.artifact and artifact.version columns
Final_Results_df[['affected.artifact', 'artifact.version']] = Final_Results_df['artifact.purl'].str.split('@', expand=True)

# remove garbage before the last "/" from affected.artifact column
regexp = ".+/"
Final_Results_df['affected.artifact'] = Final_Results_df['affected.artifact'].str.replace(regexp, '', regex=True)

# remove garbage after the first "?" from the artifact.version column
regexp = "\?.+"
Final_Results_df['artifact.version'] = Final_Results_df['artifact.version'].str.replace(regexp, '', regex=True)

# clean columns before saving
Final_Results_df["vulnerability.fix.versions"] = Final_Results_df["vulnerability.fix.versions"].str.replace("[]", '', regex=False)

Final_column_order = [
    'resource_purl',
    'vulnerabiligy_CVE',
    'image.name',
    'mitigation_url',
    'vulnerability.dataSource',
    'vulnerability_severity',
    'vulnerability.fix.state',
    'vulnerability.description',
    'affected.artifact',
    'artifact.version',
    'artifact.metadata.virtualPath',
    'vulnerability.fix.versions',
    'artifact.purl',
    'grype'
    ]


# rename the _merge column for grype
Final_Results_df.rename(columns = {'_merge':'grype'}, inplace = True)

# rename values in the new grype column: {'left_only': 'no', 'both': 'yes'}
Final_Results_df["grype"].replace({"left_only": "no", "both": "yes"}, inplace=True)

# save CVE report results
Final_Results_df[Final_column_order].to_csv(Resulting_report_name, index=False)

# save list of available fields from grype too
Available_columns_list = sorted(Available_columns)
with open('grype-fields-list.txt', 'w') as f:
    for item in Available_columns_list:
        f.write("%s\n" % item)