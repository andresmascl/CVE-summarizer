
import subprocess
import pandas as pd                     # for working with dataframes
from datetime import date               # for obtaining current date
import json
import gc


# define filenames
Original_report_name = "vulnerability-report-kaptain-main.csv"
Resulting_report_name = f"grype-report-kaptain-{date.today()}.csv"
Available_columns_file_name = "grype-fields-list.txt"


# declare variables
Needed_columns = [
    'image.name',
    'resource_purl',
    'vulnerability.id', 
    'vulnerability.dataSource', 
    'artifact.purl', 
    'vulnerability.fix.state', 
    'vulnerability.description', 
    'artifact.metadata.virtualPath',
    'vulnerability.fix.versions'
    ]


# Create dataframe for storing the final results
Final_Results_df = pd.DataFrame(columns=Needed_columns)


# Load CVE reporter report 
Original_Report_df = pd.read_csv(Original_report_name, header=0)

# Filter CVE reporter report by 'critical' CVEs only
Original_Report_df = Original_Report_df[Original_Report_df['vulnerability_severity'] == 'critical']

# Discard unnecesary columns from CVE reporter report
Original_Report_df = Original_Report_df[['resource_purl', 'vulnerability_name', 'mitigation_url', 'vulnerability_severity']]


# Create separate series for iteration
Iterable_list_of_images = pd.Series(Original_Report_df['resource_purl'])
Iterable_list_of_images = pd.Series(Iterable_list_of_images.unique())
Iterable_list_of_images = Iterable_list_of_images[~Iterable_list_of_images.str.contains('mesosphere/kubeflow-dev')]
Iterable_list_of_images = Iterable_list_of_images.reset_index(drop=True)

# Create a separate set for available columns from grype
Available_columns = set()

print("Total images:", len(Iterable_list_of_images))

for index, image in Iterable_list_of_images.items():

    print("Image", index + 1, image)


    # Create dataframe to store results for current image
    Filtered_img_CVEs_df = pd.DataFrame()


    # Format image string
    Pullable_image_name = image.replace("pkg:docker/", "")
    Pullable_image_name = Pullable_image_name.replace("@", ":")
    regex = "?repository_url="
    Split_parts = Pullable_image_name.split(regex)
    if len(Split_parts) > 1:
        Pullable_image_name = Split_parts[1] + "/" + Split_parts[0]
    else:
        Pullable_image_name = Split_parts[0]


    # Run grype scan on image
    Grype_run = subprocess.run(["./CVEs-to-CSVs.sh", Pullable_image_name.strip()], capture_output=True)


    # Load scan results in dataframe
    Current_img_CVEs_json = json.loads(Grype_run.stdout.decode('utf8'))
    Current_img_CVEs_df = pd.json_normalize(Current_img_CVEs_json['matches'])


    # Add all available columns from the dataframe to the available columns:
    Available_columns.update(Current_img_CVEs_df.columns)    
    
    
    # Add the image name and resource purl to the results
    Current_img_CVEs_df['image.name'] = Pullable_image_name
    Current_img_CVEs_df['resource_purl'] = image


    # extraer las columnas requeridas del resultado del scan
    for col in Current_img_CVEs_df:
        for needed_col in Needed_columns:
            if needed_col in Current_img_CVEs_df.columns:
                Filtered_img_CVEs_df[needed_col] = Current_img_CVEs_df[needed_col]


    # Add image results to final results
    Final_Results_df = pd.concat([Final_Results_df, Filtered_img_CVEs_df], ignore_index=True)


    gc.collect()


# add mitigation_url column from original report to final results
Final_Results_df = pd.merge(
        Original_Report_df, 
        Final_Results_df, 
        how='left', 
        left_on=['resource_purl', 'vulnerability_name'],
        right_on=['resource_purl', 'vulnerability.id'],
        suffixes=(False, False),
        indicator=True)

# quitar los resultados que solo est√©n presentes en grype y no en el CVE reporter
Final_Results_df = Final_Results_df[Final_Results_df['_merge'] != 'right_only']

# split artifact.purl column into affected.artifact and artifact.version columns
Final_Results_df[['affected.artifact', 'artifact.version']] = Final_Results_df['artifact.purl'].str.split('@', expand=True)

# remove garbage before the last "/" from affected.artifact column
regexp = ".+/"
Final_Results_df['affected.artifact'] = Final_Results_df['affected.artifact'].str.replace(regexp, '', regex=True)

# remove garbage after the first "?" from the artifact.version column
regexp = "\?.+"
Final_Results_df['artifact.version'] = Final_Results_df['artifact.version'].str.replace(regexp, '', regex=True)

# clean columns before saving
Final_Results_df["vulnerability.fix.versions"] = Final_Results_df["vulnerability.fix.versions"].str.replace("[]", '', regex=False)

Final_column_order = [
    'resource_purl',
    'vulnerability.id',
    'image.name',
    'mitigation_url',
    'vulnerability.dataSource',
    'vulnerability_severity',
    'vulnerability.fix.state',
    'vulnerability.description',
    'affected.artifact',
    'artifact.version',
    'artifact.metadata.virtualPath',
    'vulnerability.fix.versions',
    'artifact.purl',
    'grype'
    ]


# rename the _merge column for grype
Final_Results_df.rename(columns = {'_merge':'grype'}, inplace = True)

# rename values in the new grype column: {'left_only': 'no', 'both': 'yes'}
Final_Results_df["grype"].replace({"left_only": "no", "both": "yes"}, inplace=True)

# save CVE report results
Final_Results_df[Final_column_order].to_csv(Resulting_report_name, index=False)

# save list of available fields from grype too
Available_columns_list = sorted(Available_columns)
with open('grype-fields-list.txt', 'w') as f:
    for item in Available_columns_list:
        f.write("%s\n" % item)